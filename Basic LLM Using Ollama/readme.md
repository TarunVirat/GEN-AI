

This repository contains step-by-step examples and small projects exploring **LangChain**, **OpenAI**, and **Ollama** integrations.  
Each subfolder demonstrates a specific concept â€” from basic API calls to embeddings and vector storage.

---

## ðŸ“‚ Project Structure

1-Basics+Of+Langchain/
â”‚
â”œâ”€â”€ 1.1-openai/ # Intro to LangChain with OpenAI models
â”œâ”€â”€ 1.2-ollama/ # Using Ollama locally with LangChain
â”‚ â”œâ”€â”€ 1.2.1-Simpleapp.ipynb
â”‚ â””â”€â”€ app.py # Streamlit app entry point
â”‚
â”œâ”€â”€ 3.2-DataIngestion/ # Data loading and processing examples
â”œâ”€â”€ 3.3-Data Transformer/ # Data cleaning, parsing, and transformation logic
â”œâ”€â”€ 4-Embeddings/ # Text embeddings using OpenAI / HuggingFace
â”œâ”€â”€ 5-VectorStore/ # Storing embeddings in FAISS / Chroma
â”‚
â”œâ”€â”€ venv/ # (Optional) local virtual environment
â”œâ”€â”€ .env # Environment variables (API keys)
â””â”€â”€ requirements.txt # Python dependencies


## ðŸš€ Running the Streamlit App

Make sure you have your environment active (Conda or venv):

```bash
conda activate langchain_env
# or
.\venv\Scripts\activate

Then install dependencies:

pip install -r requirements.txt

Run the Streamlit app:

streamlit run 1.2-ollama/app.py
